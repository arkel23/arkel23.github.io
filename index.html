<!DOCTYPE html>
<html>
    <head>
        <meta content="text/html; charset=utf-8" http-equiv="content-type">
        <meta content="width=device-width, initial-scale=1" name="viewport">
        <meta name="description" content="Arkel's Notes: personal page and blog for Edwin Arkel Rios">
        <meta name="author" content="Edwin Arkel Rios">
        <meta name="keywords" content="Machine Learning, ML, Deep Learning
        , DL, Computer Vision, CV, Knowledge Distillation, KD,
        Self-Supervised Learning, SSL, Parameter-Efficient Fine-Tuning, PEFT,
        Generative Adversarial Network, GAN, Artificial Intelligence, AI,
        Data Science, DS, Tutorials, Research">
        <meta http-equiv="content-type" content="text/html; charset=windows-1252">
        <title>Arkel's Notes: Edwin Arkel Rios Blog</title>
        <base href="./">
        <link href='styles/sakura_lil.css' id="sakura-css" rel='stylesheet' type='text/css'>
        <link rel="canonical" href="https://arkel23.github.io/">
        <style>
            img {
                margin-bottom: 0;
            }
            td {
                vertical-align: top;
            }
            .img {
                vertical-align: middle;
            }
            .project {
                font-size: 17px;
            }
            .highlighted {
                font-size:      20px;
                font-weight:    bold;
            }
            #footer {
                text-align: center;
                font-size: 16px;
            }
            .logo {
                border-radius: 80%;
                width: 30px;
            }


        </style>
    </head>

    <body>  
        <header class="site-header" role="banner" id="header-bar">
            <div class="wrapper"> 
                <a class="site-title" href="https://arkel23.github.io/">Arkel's Notes</a>
                
                <nav class="site-nav">
                    <a class="page-link" href="https://hackmd.io/@arkel23">Blog Posts</a>
                </nav>
            </div>
        </header>

        <h4>About Me</h4>
        
        <table style="width:95%;">
            <colgroup>
            <col width="40%">
            <col width="60%">
            </colgroup>
            <tbody>
            <tr>
                <td align="center" class="img">
                    <img width="200" src="assets/me.jpg" border="0">
                </td>
                <td align="right" style="vertical-align: middle">
                    <div class="highlighted">Edwin Arkel Rios</div>
                    PhD Student in EECS<br>
                    National Yang Ming Chiao Tung University<br>
                    Hsinchu, Taiwan<br><br>

                    edwinarkel.rios@gmail.com<br>
                    [<a href="https://github.com/arkel23" border="0">GitHub</a>]
                    [<a href="assets/cv.pdf" border="0">Resume</a>]
                </td>
            </tr>
            </tbody>
        </table>

        <hr>
        <p align="justify">
            My name's Edwin and I come from Panama. I received the B.S. degree in
            Energy Engineering from National Cheng Kung University (NCKU), Tainan,
            Taiwan, in 2019. I enrolled National Yang Ming Chiao Tung University
            (NYCU) to pursue a M.S. and then a Ph.D. degree in Electrical
            Engineering and Computer Science (EECS), in 2019 and 2021,
            respectively, where I have been co-supervised by Professor Bo-Cheng
            Lai (賴伯承) and Professor Min-Chun Hu (胡敏君).<br><br>

            My research is focused on the design of efficient deep learning models.
            In particular, I have done work on time-series for heart-rate
            monitoring, model compression using knowledge distillation and
            self-supervised learning, and efficient fine-grained image recognition
            systems incorporating parameter-efficient transfer learning,
            token pruning for vision transformers, and efficient discriminative
            feature selection mechanisms.
        </p>
        <hr>

        <h4>Publications</h4>
        <table style="width:100%">
            <colgroup>
            <col width="25%">
            <col width="75%">
            </colgroup>
            <tbody>

                <tr>
                    <td class="img">
                        <img align="center" src="assets/glsim.png" border="0">
                    </td>
                    <td align="left">
                        <b>Cross-Layer Cache Aggregation for Token Reduction in
                            Ultra-Fine-Grained Image Recognition. ICASSP 25</b><br>
                        Plug-and-play modules to avoid information loss when
                        applying token pruning methods for datasets with
                        small inter-class differences.<br>
                        Thorough experiments across diverse datasets, backbones,
                        token reduction methods, image sizes, and keep rates
                        show our method enables significant cost savings while
                        maintaining high accuracy.<br>
                        [<a href="https://github.com/arkel23/clca">Source code</a>]
                        [<a href="https://arxiv.org/abs/2501.00243">Paper</a>]
                        <br>
                    </td>
                    <tr>

                <tr>
                <td class="img">
                    <img align="center" src="assets/dsila.png" border="0">
                </td>
                <td align="left">
                    <b>Down-Sampling Inter-Layer Adapter for Parameter and
                        Computation Efficient Ultra-Fine-Grained
                        Image Recognition. ECCV EFM Workshop 24</b><br>
                    Addresses attention collapse under wide domain gap adaptation
                    settings by proposing down-sampling adapter module.<br>
                    Similar accuracy but 123x less trainable parameters
                    compared to SotA.<br>
                    [<a href="https://github.com/arkel23/DownSamplingInterLayerAdapter">Source code</a>]
                    [<a href="https://arxiv.org/abs/2409.11051">Paper</a>]
                    <br>
                </td>
                <tr>

                <tr>
                <td class="img">
                    <img align="center" src="assets/glsim.png" border="0">
                </td>
                <td align="left">
                    <b>Global-Local Similarity for Efficient Fine-Grained
                        Image Recognition with Vision Transformers. ISCAS 25</b><br>
                    Similarity between global and local representation as criteria
                    for discriminative region selection criteria in FGIR.<br>
                    Thorough experiments across 10 FGIR datasets covering
                    variety of settings including image size and AugReg combinations.<br>
                    Our proposed model obtains best accuracy on 8 / 10 at
                    much less cost than best on others.<br>
                    [<a href="https://github.com/arkel23/GLSim">Source code</a>]
                    [<a href="https://arxiv.org/abs/2407.12891">Paper (arXiv)</a>]
                    <br>
                </td>
                <tr>

                <tr>
                <td class="img">
                    <img align="center" src="assets/animesion.png" border="0">
                </td>
                <td align="left">
                    <b>Anime Character Recognition using Intermediate Features
                        Aggregation. ISCAS 2022</b><br>
                    Intermediate features aggregation classification head for
                    reducing sensitivity to hyperparameters in ViTs at
                    low computational cost.<br>
                    Experiments on how model architecture and hyperparameter
                    affect classification performance.<br>
                    [<a href="https://github.com/arkel23/animesion/classification_tagging">Source code</a>]
                    [<a href="https://ieeexplore.ieee.org/document/9937519">Paper</a>]
                    <br>
                </td>
                <tr>

                <tr>
                <td class="img">
                    <img align="center" src="assets/ifacd.png" border="0">
                </td>
                <td align="left">
                    <b>IFACD: Intermediate Features Augmented Contrastive
                        Distillation. ICLR CSS Workshop 2022</b><br>
                    Extend contrastive learning framework (in particular
                    SimCLR-like) to support features from intermediate layers
                    of a particular image as additional positive pairs and
                    intermediate features from other images in batch as
                    negative pairs, reducing reliance on augmentations pairs
                    and large batch size requirements.<br>
                    Apply proposed contrastive loss in a knowledge distillation
                    framework where intermediate features are extracted
                    using a frozen teacher and student learns using a combined
                    contrastive, distillation, and supervised cross-entropy loss.<br>
                    Experiments with a variety of teacher-student combinations
                    show our method obtains favorable accuracy at
                    a competitive computational cost compared to alternatives.<br>
                    [<a href="https://github.com/arkel23/IntermediateFeaturesAugmentedRepDistiller">Source Code</a>]
                    [<a href="https://iclr.cc/virtual/2022/workshop/9069">Recorded Presentation (Starts at 2:47:50)</a>]
                    [<a href="assets/IFACD.pdf">Slides</a>]
                    <br>
                </td>
                <tr>

                <tr>
                <td class="img">
                    <img align="center" src="assets/rppg_demo.png" border="0">
                </td>
                <td align="left">
                    <b>DLPrPPG: Development and Design of Deep Learning Platform
                        for Remote Photoplethysmography. ISCAS 2022</b><br>
                    <b>Parametric Study of Performance of Remote Photopletysmography System. ISCAS 2021</b><br>
                    Systematic studies of remote photoplethysmography (RPPG)
                    design hyperparameters (face detection method, region of
                    interest selection scheme, sliding window size,
                    preprocessing and postprocessing algorithm choice)
                    and their effects on heart rate prediction accuracy in
                    relation to computational cost using C++, Python and OpenCV.<br>
                    [<a href="https://ieeexplore.ieee.org/document/9937698">Paper ISCAS 2022</a>]
                    [<a href="https://ieeexplore.ieee.org/document/9401620">Paper ISCAS 2021</a>]
                    <br>
                </td>
                <tr>

            </tbody>
        </table>
    
        
        <h4>Projects</h4>
        <table style="width:100%">
            <colgroup>
            <col width="25%">
            <col width="75%">
            </colgroup>
            <tbody>

                <tr>
                    <td class="img">
                        <img align="center" src="assets/anime_demo.gif" border="0">
                    </td>
                    <td align="left">
                        <b>Vision Transformers for Anime Character Face Recognition</b> <br>
                        Image classification of anime character faces using
                        state-of-the-art for image recognition: vision transformers.<br>
                        Revamped a dataset for this task, DAF:re: almost 500 K
                        images and more than 3 K classes.<br>
                        Conducted experiments on both CNN and self-attention
                        based models, and explored for the first-time the
                        hyperparameter tuning (mini-batch and image size) of
                        vision transformers for out-of-domain data.<br>
                        [<a href="https://github.com/arkel23/animesion">Source code</a>]
                        [<a href="https://arxiv.org/abs/2101.08674">Paper on DAF:re</a>]
                        <br>
                    </td>
                </tr>


                <tr>
                    <td class="img">
                        <img align="center" src="assets/dip_deblurgan_demo.jpg" border="0">
                    </td>
                    <td align="left">
                        <b>DeblurGAN for Deblurring of Videos</b> <br>
                        Done in Python, using OpenCV and PyTorch.<br>
                        Final project for Digital Image Processing course (108-1).<br>
                        Also included slides for midterm presentation covering
                        DeblurGANv2 paper. <br>
                        [<a href="assets/dip_deblurgan_poster.pdf">Final Project Poster</a>]
                        [<a href="assets/dip_deblurgan_proposal.pdf">DeblurGANv2 Paper Slides</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td class="img">
                        <img align="center" src="assets/dl_demo.png" border="0">
                    </td>
                    <td align="left">
                        <b>Computer Vision for Autonomous Driving</b> <br>
                        Done in Python, making use of TensorFlow, Keras,
                        OpenCV, and ROS. <br>
                        Final project for Deep Learning course (108-1). <br>
                        Also included slides for midterm presentation covering
                        VGG network paper. <br>
                        [<a href="assets/dl_vgg.pdf">VGG Paper Slides</a>]
                        [<a href="assets/dl_final.pdf">Final Project Slides</a>]
                        <br>
                    </td>
                </tr>

            </tbody>
        </table>
    
        <hr>
        <div id="footer">
            <div>
            <a href="https://hackmd.io/@arkel23">Arkel's Notes: Edwin Arkel Rios's Blog | </a>
            <a href="https://arkel23.github.io/">About Me | </a>
            <a href="https://github.com/arkel23/arkel23.github.io">Webpage Source Code</a>
            </div>
            <div style="padding-top: 10px;">
                <a href="https://github.com/arkel23" target="_blank">
                    <img class="logo" src="assets/logo_github.png">
                </a>
                <a href="mailto:edwinarkel.rios@gmail.com" target="_blank">
                    <img class="logo" src="assets/logo_gmail.png">
                </a>
                <a href="http://discordapp.com/users/344795970283896832" target="_blank">
                    <img class="logo" src="assets/logo_discord.png">
                </a>
                <a href="https://www.instagram.com/arkeldiary/" target="_blank">
                    <img class="logo" src="assets/logo_instagram.png">
                </a>
            </div>
        </div>

    </body>
</html>
