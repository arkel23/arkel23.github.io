<!-- 
Copied from 
https://github.com/richzhang/richzhang.github.io/blob/master/index.html
https://richzhang.github.io/
 -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
    <title>Richard Zhang - Research Scientist, Adobe Research </title>
<style type="text/css"></style></head>
<body><table border="0" width="980px" align="center"><tbody><tr><td>

    </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
            <img src="images/rilogo.png"> -->
    <br>
    <table style="font-size: 11pt;" border="0" width="100%">
        <tbody><tr>
            <td width="50%">
                <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                <!-- <img width="300" src="./index_files/mypic2.jpg" border="0"> -->
                <img width="250" src="./index_files/mypic3.jpg" border="0">
            </td>
            <td>
                <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                    <b>Richard Zhang</b><br><br>
                </font>
                <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                    Research Scientist<br>
                    Adobe Research<br>
                    San Francisco, CA<br><br>
                    rizhang at adobe.com<br>
                    [<a href="https://github.com/richzhang" border="0">GitHub</a>]
                    [<a href="https://scholar.google.com/citations?user=LW8ze_UAAAAJ&hl=en" border="0">Google Scholar</a>]<br>
                    [<a href="index_files/CV.pdf" border="0">Resume/CV</a>]
                    [<a href="https://twitter.com/rzhang88" border="0">Twitter</a>]
                    [<a href="bio.txt" border="0">Bio</a>]<br>
                </font>
            </td>
        </tr>
    </tbody></table> 
    <p>
    </p><hr size="2" align="left" noshade="">
    <p>
    
    <font face="helvetica, ariel, &#39;sans serif&#39;"> 
    <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
    My research interests are in computer vision, machine learning, deep learning, graphics, and image processing. I obtained a PhD at UC Berkeley, advised by Prof. <a href="http://www.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros</a>. I obtained BS and MEng degrees from Cornell University in ECE. I often collaborate with academic researchers, either through internships or university collaboration.

    <!-- <br><br> -->
    </p><hr size="2" align="left" noshade="">

    <h3>News </h3>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <span style="font-size: 10pt;">
        <b>[Sept 2020]</b> Few updates regarding <a href="https://richzhang.github.io/antialiased-cnns/">Antialiasing CNNs</a> [ICML 2019], which can <b>stabilize and improve the backbone for your application</b>:<br>
        - Easy installation: <mark><font face="Courier">pip install antialiased-cnns</font></mark> and 
        <mark><font face="Courier" color="red">import</font>
        <font face="Courier">antialiased_cnns; model</font>
        <font face="Courier" color="blue"> = </font>
        <font face="Courier">antialiased_cnns.</font><font face="Courier" color="#6c53b5">resnet50</font><font face="Courier">(pretrained=</font>
        <font face="Courier" color="blue">True)</font></mark><br>
        - For more information, including "What is Aliasing?", see my <a href="https://youtu.be/8CXrplBG-SE?t=1049">guest lecture</a> [15 min] in SFU CMPT 361, Intro to Vision, Sampling and Aliasing lecture.<br>
        - A nice followup work,
        <a href="https://maureenzou.github.io/ddac/">Delving Deeper into Antialiasing in Convnets</a> by Zou, Xiao, Yu, & Lee, won best paper at BMVC 2020. Check it out!<br>
        <b>[Aug 2020]</b> I gave a talk on <a href="https://www.youtube.com/watch?v=CYdYWeTE-CI">Detecting Generated Imagery, Deep and Shallow</a> (35 min) at the <a href="https://sense-human.github.io/">Sensing Humans</a> workshop at ECCV.<br>
        <b>[Aug 2020]</b> I gave a talk on <a href="https://www.youtube.com/watch?v=aM86tOniH90">Style and Structure Disentanglement for Image Manipulation</a> (30 min) at the <a href="https://data.vision.ee.ethz.ch/cvl/aim20/">Advances in Image Manipulation</a> workshop at ECCV.<br>
        <b>[Aug 2020]</b> I gave a talk on <a href="https://www.bilibili.com/video/BV1e7411c7kR?p=46">Analyzing Artifacts in Discriminative and Generative Models</a> (40 min) at the GAMES webinar.<br>
        <b>[July 2020]</b> Our work on using contrastive learning for unpaired translation was accepted to ECCV.<br>
        <b>[July 2020]</b> Our work on inverting GANs was accepted to ECCV as an oral.<br>
        <b>[July 2020]</b> See our new work on Swapping Autoencoders below.<br>
        <b>[July 2020]</b> Our work on audio perceptual metrics was accepted to Intespeech.<br>
        <b>[Feb 2020]</b> I served as an Area Chair for CVPR 2020 and spoke on <a href="https://www.youtube.com/watch?v=aNDwHRxWTa0">Analyzing CNN Artifacts in Discriminative and Generative Models</a> (11 min). The second half includes our "Detecting CNN-generated images" work, just accepted to CVPR.<br>
        <!-- <b>[Dec 2019]</b> See our new work on detecting CNN-generated images below.<br> -->
        <!-- <b>[Nov 2019]</b> I presented our "Detecting Photoshop" ICCV19 work at <a href="https://www.youtube.com/watch?v=21lj8tCSMkg">Adobe MAX</a> (5 min), on stage with John Mulaney (aka Peter Porker/Spider-Ham)!<br> -->
        <!-- <b>[Oct 2019]</b> Thank you <a href="https://twitter.com/Oxford_VGG/status/1184087868857290752">Oxford</a> and UCL for hosting me.<br> -->
        <!-- <b>[Oct 2019]</b> This <a href="http://video.tv.adobe.com/v/28291">video</a> shows interactive colorization in Photoshop Elements 2020, based on our SIGGRAPH 2017 work.<br> -->
        <!-- <b>[Sept 2019]</b> See our new work on interactive sketch to image synthesis below.<br> -->
        <!-- <b>[Jun 2019]</b> See our new work on detecting Photoshopped images below.<br> -->
        <!-- <b>[May 2019]</b> Our work on anti-aliasing convolutional networks has been accepted to ICML 2019. Try anti-aliasing your convnet <a href="https://github.com/adobe/antialiased-cnns">here</a>!<br> -->
        <!-- <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br> -->
        <!-- <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!<br> -->
        <!-- <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco! -->
        </span>

    </p><hr size="2" align="left" noshade="">

    <h3>Internship </h3>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <span style="font-size: 10pt;">
        If you have similar interests and are interested in collaborating during a summer 2021 internship, I'd be happy to hear from you. <b>Please apply <a href="https://research.adobe.com/internships">here</a></b> and then
        <!-- I would be also happy to hear from you. <b>Timing-wise, please contact me after the CVPR deadline (Nov 16)</b>, unless you have expiring offers. This is because I am still focusing on current projects and do not know headcount for next year. -->
        tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. Interns are typically PhD students; the number of slots is limited, so we unfortunately cannot accept everyone.
        </span>
    </font>

    </p><hr size="2" align="left" noshade="">

    <h2>Publications </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="15">
            <tbody>


            <tr>
                <td width="30%" align=center>
                <!-- height="74" -->
                    <!-- <center> -->
                    <img height="80" align="center" src="https://taesung.me/SwappingAutoencoder/index_files/church_style_swaps.gif" border="0"> &nbsp;
                    <img height="80" align="center" src="https://taesung.me/SwappingAutoencoder/index_files/tree_smaller.gif" border="0"> &nbsp;
                    <!-- </center> -->
                </td>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Swapping Autoencoder for Deep Image Manipulation</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://taesung.me/">Taesung Park</a>, <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, <a href="https://research.adobe.com/person/jingwan-lu/">Jingwan Lu</a>, <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, Richard Zhang<br>
                    To appear in NeurIPS, 2020. <br>
                    [<a href="https://arxiv.org/abs/2007.00653">Paper</a>]
                    [<a href="https://taesung.me/SwappingAutoencoder">Webpage</a>]
                    [<a href="https://www.youtube.com/watch?v=0elW11wRNpg&feature=emb_title">Video</a>]
                    [<a href="https://taesung.me/SwappingAutoencoder/index_files/bibtex_arxiv2020.txt">Bibtex</a>]
                    <br>
                </td>
            </tr>
            <tr>
                <td width="30%" align=center>
                <!-- height="74" -->
                    <!-- <center> -->
                    <img height="100" align="center" src="./index_files/fewshot_neurips20.jpg" border="0"> &nbsp;
                    <!-- </center> -->
                </td>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Few-shot Image Generation with Elastic Weight Consolidation</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yijunmaverick.github.io/">Yijun Li</a>, Richard Zhang, <a href="https://research.adobe.com/person/jingwan-lu/">Jingwan Lu</a>, <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a><br>
                    To appear in NeurIPS, 2020. <br>
                    [<a href="https://proceedings.neurips.cc/paper/2020/file/b6d767d2f8ed5d21a44b0e5886680cb9-Paper.pdf">Paper</a>]
                    [<a href="https://proceedings.neurips.cc/paper/2020/file/b6d767d2f8ed5d21a44b0e5886680cb9-Supplemental.pdf">Supplemental</a>]
                    [<a href="./index_files/bibtex_fewshot_neurips20.txt">Bibtex</a>]
                    <br>
                </td>
            </tr>